{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/emeraldgoose/bad-korean-tokenizer/resolve/main/config.json from cache at /opt/ml/.cache/huggingface/transformers/440db990a6715f3d4c1f93091ed1da220bb5fc5c7c2f6e21adbb20adb249923b.2ccb1233a18c0cf90e39ee2d88f08019fe65c376fa142a098d3108cb5fab9d28\n",
      "Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50142\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/beomi/KcELECTRA-base/resolve/main/config.json from cache at /opt/ml/.cache/huggingface/transformers/61dd2bdbb7e56ff51fdc66b6f0d1973d2d806cd616d38a149f1bfd2753babc3c.ba488f0d9624511a98ed83af3e8f6b33fe20b502e2cfb16ee9858a6b6f521982\n",
      "Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50135\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/beomi/KcELECTRA-base/resolve/main/pytorch_model.bin from cache at /opt/ml/.cache/huggingface/transformers/e3de2d33772a49e4df71e30cb03502288144cfc1fad4a5f21d50228d3ea31dd1.e7aebfaefee4224375864d9a78653681e8d98c76b2e37cebeddf5ec46de5395d\n",
      "Some weights of the model checkpoint at beomi/KcELECTRA-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file https://huggingface.co/emeraldgoose/bad-korean-tokenizer/resolve/main/config.json from cache at /opt/ml/.cache/huggingface/transformers/440db990a6715f3d4c1f93091ed1da220bb5fc5c7c2f6e21adbb20adb249923b.2ccb1233a18c0cf90e39ee2d88f08019fe65c376fa142a098d3108cb5fab9d28\n",
      "Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50142\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/emeraldgoose/bad-korean-tokenizer/resolve/main/vocab.txt from cache at /opt/ml/.cache/huggingface/transformers/9142b880bd225d1b9a777a705dd9991412a38110c9d73fb64f0f00d09b2cb158.a59cda3abc7fe9224f5b3344b4ac76b515bb2d86124f7ab6cfd6f7be710361c3\n",
      "loading file https://huggingface.co/emeraldgoose/bad-korean-tokenizer/resolve/main/tokenizer.json from cache at /opt/ml/.cache/huggingface/transformers/f8308a07def7888d2871ece8673387a7cb96a361bc34ed20f390e6142062740d.9ddca11d921229a0defd289d33487faf903ccbec1bb49e6a3311b01b98ed0360\n",
      "loading file https://huggingface.co/emeraldgoose/bad-korean-tokenizer/resolve/main/added_tokens.json from cache at /opt/ml/.cache/huggingface/transformers/2eed3052a35bbdc98689632719e4f4696d31846c1f91417a620c8d2229fe6ddc.7eae23604af7c23db94b3fe2e125c418d7d421d29ddcb82949e9f63e2ebda334\n",
      "loading file https://huggingface.co/emeraldgoose/bad-korean-tokenizer/resolve/main/special_tokens_map.json from cache at /opt/ml/.cache/huggingface/transformers/99175518058a64c12bf590a87ffe99129d52f87552c82aa9a79702d4fbdc60e8.f982506b52498d4adb4bd491f593dc92b2ef6be61bfdbe9d30f53f963f9f5b66\n",
      "loading file https://huggingface.co/emeraldgoose/bad-korean-tokenizer/resolve/main/tokenizer_config.json from cache at /opt/ml/.cache/huggingface/transformers/b70c6939ae5ec984e96cbb985ff7e720966acfb8dfd50263bcd134e02e0788c5.1825a010fe27b5f50bf12b8d93a7a4ed894a4a21bb9a259965e2521087d66bd8\n",
      "loading configuration file https://huggingface.co/emeraldgoose/bad-korean-tokenizer/resolve/main/config.json from cache at /opt/ml/.cache/huggingface/transformers/440db990a6715f3d4c1f93091ed1da220bb5fc5c7c2f6e21adbb20adb249923b.2ccb1233a18c0cf90e39ee2d88f08019fe65c376fa142a098d3108cb5fab9d28\n",
      "Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"tokenizer_class\": \"BertTokenizer\",\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50142\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\"emeraldgoose/bad-korean-tokenizer\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"beomi/KcELECTRA-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('emeraldgoose/bad-korean-tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1107"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./curse.csv', index_col=0)\n",
    "# eval_df = pd.read_csv('./eval_data.csv', index_col=0)\n",
    "# len(train_df), len(eval_df)\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-c5ea465d669f8c36\n",
      "Reusing dataset csv (/opt/ml/.cache/huggingface/datasets/csv/default-c5ea465d669f8c36/0.0.0/bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae8d20b297540d19b97ef0c885848e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = load_dataset('csv', data_files=['curse.csv'], delimiter=',')\n",
    "# eval_dataset = load_dataset('csv', data_files=['eval_data.csv'], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type(train_dataset), type(eval_dataset)\n",
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'text', 'label'],\n",
       "        num_rows: 1107\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset['train'].remove_columns('Unnamed: 0')\n",
    "# eval_dataset = eval_dataset['train'].remove_columns('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(train_dataset), type(eval_dataset)\n",
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_dataset(dataset, tokenizer):\n",
    "    tokenized = tokenizer(\n",
    "        dataset['text'],\n",
    "        return_tensors='pt',\n",
    "        padding=True,\n",
    "        max_length=256,\n",
    "        add_special_tokens=True,\n",
    "    )\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/lightweight/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2229: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  \"`max_length` is ignored when `padding`=`True` and there is no truncation strategy. \"\n"
     ]
    }
   ],
   "source": [
    "train_label = train_dataset['label']\n",
    "# eval_label = eval_dataset['label']\n",
    "\n",
    "train_dataset = tokenized_dataset(train_dataset, tokenizer)\n",
    "# eval_dataset = tokenized_dataset(eval_dataset, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# type(train_dataset), type(eval_dataset)\n",
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CL_Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\" Dataset 구성을 위한 class.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset, labels):\n",
    "        self.dataset = dataset\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach()\n",
    "                for key, val in self.dataset.items()}\n",
    "        item['label'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = CL_Dataset(train_dataset, train_label)\n",
    "# eval_set = CL_Dataset(eval_dataset, eval_label)\n",
    "# len(train_set), len(eval_set)\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    2,  2896,  4225, 14257,  4030,   116,  4770,     3,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'label': tensor(0)}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device = {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50144, 768)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(tokenizer.vocab_size + len(tokenizer.get_added_vocab()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(50144, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "def compute_metrics(preds):\n",
    "    labels = preds.label_ids\n",
    "    preds = preds.predictions.argmax(-1)\n",
    "    return {'f1_score': f1_score(labels,preds), 'acc' : accuracy_score(labels,preds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    do_train=True,\n",
    "    output_dir=f'./results/',\n",
    "    save_total_limit=5,\n",
    "    save_steps=10,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    # weight_decay=1e-6,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_set,\n",
    "    # eval_dataset=eval_set,\n",
    "    eval_dataset=train_set,\n",
    "    compute_metrics=compute_metrics,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 1107\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 350\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='350' max='350' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [350/350 03:07, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.424500</td>\n",
       "      <td>0.359991</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.778681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.383800</td>\n",
       "      <td>0.326976</td>\n",
       "      <td>0.370607</td>\n",
       "      <td>0.822042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.399100</td>\n",
       "      <td>0.293939</td>\n",
       "      <td>0.734300</td>\n",
       "      <td>0.900632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.349300</td>\n",
       "      <td>0.265771</td>\n",
       "      <td>0.838174</td>\n",
       "      <td>0.929539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.310300</td>\n",
       "      <td>0.241394</td>\n",
       "      <td>0.856597</td>\n",
       "      <td>0.932249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.270600</td>\n",
       "      <td>0.215556</td>\n",
       "      <td>0.868526</td>\n",
       "      <td>0.940379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.276500</td>\n",
       "      <td>0.196098</td>\n",
       "      <td>0.883910</td>\n",
       "      <td>0.948509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.200700</td>\n",
       "      <td>0.177484</td>\n",
       "      <td>0.891616</td>\n",
       "      <td>0.952123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.213900</td>\n",
       "      <td>0.164356</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.956640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.202100</td>\n",
       "      <td>0.146851</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.963866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.194400</td>\n",
       "      <td>0.131310</td>\n",
       "      <td>0.929961</td>\n",
       "      <td>0.967480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.202200</td>\n",
       "      <td>0.136471</td>\n",
       "      <td>0.916201</td>\n",
       "      <td>0.959350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.198300</td>\n",
       "      <td>0.106994</td>\n",
       "      <td>0.957364</td>\n",
       "      <td>0.980126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.136600</td>\n",
       "      <td>0.096864</td>\n",
       "      <td>0.957198</td>\n",
       "      <td>0.980126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.106700</td>\n",
       "      <td>0.088479</td>\n",
       "      <td>0.959064</td>\n",
       "      <td>0.981030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.080996</td>\n",
       "      <td>0.962818</td>\n",
       "      <td>0.982836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.119100</td>\n",
       "      <td>0.073805</td>\n",
       "      <td>0.966862</td>\n",
       "      <td>0.984643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.144800</td>\n",
       "      <td>0.065957</td>\n",
       "      <td>0.970874</td>\n",
       "      <td>0.986450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.093400</td>\n",
       "      <td>0.071447</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.983740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.092100</td>\n",
       "      <td>0.059225</td>\n",
       "      <td>0.970986</td>\n",
       "      <td>0.986450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.055734</td>\n",
       "      <td>0.970874</td>\n",
       "      <td>0.986450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.075700</td>\n",
       "      <td>0.055192</td>\n",
       "      <td>0.974855</td>\n",
       "      <td>0.988257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.098900</td>\n",
       "      <td>0.053739</td>\n",
       "      <td>0.974855</td>\n",
       "      <td>0.988257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.087100</td>\n",
       "      <td>0.048669</td>\n",
       "      <td>0.980545</td>\n",
       "      <td>0.990967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.056100</td>\n",
       "      <td>0.045307</td>\n",
       "      <td>0.980469</td>\n",
       "      <td>0.990967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.073900</td>\n",
       "      <td>0.042043</td>\n",
       "      <td>0.982318</td>\n",
       "      <td>0.991870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>0.040681</td>\n",
       "      <td>0.984252</td>\n",
       "      <td>0.992773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.039405</td>\n",
       "      <td>0.982318</td>\n",
       "      <td>0.991870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.033700</td>\n",
       "      <td>0.039472</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.993677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.038700</td>\n",
       "      <td>0.039131</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.993677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.044300</td>\n",
       "      <td>0.038484</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.993677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>0.037893</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.993677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.037516</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.993677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.079400</td>\n",
       "      <td>0.037048</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.993677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.037049</td>\n",
       "      <td>0.986301</td>\n",
       "      <td>0.993677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-10\n",
      "Configuration saved in ./results/checkpoint-10/config.json\n",
      "Model weights saved in ./results/checkpoint-10/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-20\n",
      "Configuration saved in ./results/checkpoint-20/config.json\n",
      "Model weights saved in ./results/checkpoint-20/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-30\n",
      "Configuration saved in ./results/checkpoint-30/config.json\n",
      "Model weights saved in ./results/checkpoint-30/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-50] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-40\n",
      "Configuration saved in ./results/checkpoint-40/config.json\n",
      "Model weights saved in ./results/checkpoint-40/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-50\n",
      "Configuration saved in ./results/checkpoint-50/config.json\n",
      "Model weights saved in ./results/checkpoint-50/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-150] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-60\n",
      "Configuration saved in ./results/checkpoint-60/config.json\n",
      "Model weights saved in ./results/checkpoint-60/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-10] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-70\n",
      "Configuration saved in ./results/checkpoint-70/config.json\n",
      "Model weights saved in ./results/checkpoint-70/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-20] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-80\n",
      "Configuration saved in ./results/checkpoint-80/config.json\n",
      "Model weights saved in ./results/checkpoint-80/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-30] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-90\n",
      "Configuration saved in ./results/checkpoint-90/config.json\n",
      "Model weights saved in ./results/checkpoint-90/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-40] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-100\n",
      "Configuration saved in ./results/checkpoint-100/config.json\n",
      "Model weights saved in ./results/checkpoint-100/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-50] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-110\n",
      "Configuration saved in ./results/checkpoint-110/config.json\n",
      "Model weights saved in ./results/checkpoint-110/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-60] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-120\n",
      "Configuration saved in ./results/checkpoint-120/config.json\n",
      "Model weights saved in ./results/checkpoint-120/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-70] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-130\n",
      "Configuration saved in ./results/checkpoint-130/config.json\n",
      "Model weights saved in ./results/checkpoint-130/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-80] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-140\n",
      "Configuration saved in ./results/checkpoint-140/config.json\n",
      "Model weights saved in ./results/checkpoint-140/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-90] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-150\n",
      "Configuration saved in ./results/checkpoint-150/config.json\n",
      "Model weights saved in ./results/checkpoint-150/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-160\n",
      "Configuration saved in ./results/checkpoint-160/config.json\n",
      "Model weights saved in ./results/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-110] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-170\n",
      "Configuration saved in ./results/checkpoint-170/config.json\n",
      "Model weights saved in ./results/checkpoint-170/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-120] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-180\n",
      "Configuration saved in ./results/checkpoint-180/config.json\n",
      "Model weights saved in ./results/checkpoint-180/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-130] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-190\n",
      "Configuration saved in ./results/checkpoint-190/config.json\n",
      "Model weights saved in ./results/checkpoint-190/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-140] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-200\n",
      "Configuration saved in ./results/checkpoint-200/config.json\n",
      "Model weights saved in ./results/checkpoint-200/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-150] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-210\n",
      "Configuration saved in ./results/checkpoint-210/config.json\n",
      "Model weights saved in ./results/checkpoint-210/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-220\n",
      "Configuration saved in ./results/checkpoint-220/config.json\n",
      "Model weights saved in ./results/checkpoint-220/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-170] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-230\n",
      "Configuration saved in ./results/checkpoint-230/config.json\n",
      "Model weights saved in ./results/checkpoint-230/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-180] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-240\n",
      "Configuration saved in ./results/checkpoint-240/config.json\n",
      "Model weights saved in ./results/checkpoint-240/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-190] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-250\n",
      "Configuration saved in ./results/checkpoint-250/config.json\n",
      "Model weights saved in ./results/checkpoint-250/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-260\n",
      "Configuration saved in ./results/checkpoint-260/config.json\n",
      "Model weights saved in ./results/checkpoint-260/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-210] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-270\n",
      "Configuration saved in ./results/checkpoint-270/config.json\n",
      "Model weights saved in ./results/checkpoint-270/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-220] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-280\n",
      "Configuration saved in ./results/checkpoint-280/config.json\n",
      "Model weights saved in ./results/checkpoint-280/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-230] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-290\n",
      "Configuration saved in ./results/checkpoint-290/config.json\n",
      "Model weights saved in ./results/checkpoint-290/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-240] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-300\n",
      "Configuration saved in ./results/checkpoint-300/config.json\n",
      "Model weights saved in ./results/checkpoint-300/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-250] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-310\n",
      "Configuration saved in ./results/checkpoint-310/config.json\n",
      "Model weights saved in ./results/checkpoint-310/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-260] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-320\n",
      "Configuration saved in ./results/checkpoint-320/config.json\n",
      "Model weights saved in ./results/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-270] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-330\n",
      "Configuration saved in ./results/checkpoint-330/config.json\n",
      "Model weights saved in ./results/checkpoint-330/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-280] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-340\n",
      "Configuration saved in ./results/checkpoint-340/config.json\n",
      "Model weights saved in ./results/checkpoint-340/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-290] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1107\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ./results/checkpoint-350\n",
      "Configuration saved in ./results/checkpoint-350/config.json\n",
      "Model weights saved in ./results/checkpoint-350/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-300] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results/checkpoint-340 (score: 0.03704802319407463).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=350, training_loss=0.1546224845307214, metrics={'train_runtime': 187.2843, 'train_samples_per_second': 29.554, 'train_steps_per_second': 1.869, 'total_flos': 230394326181300.0, 'train_loss': 0.1546224845307214, 'epoch': 5.0})"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./config.json\n",
      "Model weights saved in ./pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained('./')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e31c68abf1d5dd3f9e2269f23eadf1b199587e56c0618a30760176a65ebfcab4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('lightweight': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
